{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<gensim.models.word2vec.Word2Vec at 0x1c8f34948e0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<gensim.models.word2vec.Word2Vec at 0x1c891d48b50>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word Embeddings\n",
    "\n",
    "https://neptune.ai/blog/word-embeddings-guide"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'h': 0,\n 'k': 1,\n 'c': 2,\n 'a': 3,\n '.': 4,\n 'u': 5,\n 'l': 6,\n 'p': 7,\n 'w': 8,\n 'm': 9,\n 'i': 10,\n 't': 11,\n 'T': 12,\n 's': 13,\n 'n': 14,\n 'd': 15,\n 'y': 16,\n 'o': 17,\n 'e': 18,\n 'f': 19,\n 'r': 20}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sentence = \"This introduced a neural network architecture approach that laid the foundation for many current approaches. \"\n",
    "#making a list of all characters without the spaces between\n",
    "word_list = \" \".join(raw_sentence).split()\n",
    "#making the list elements unique\n",
    "word_list = list(set(word_list))\n",
    "#iterate the word_list, to make a dictionary as map\n",
    "word2id = {w: i for i, w in enumerate(word_list)}\n",
    "id2word = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word2id)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['h',\n 'k',\n 'c',\n 'a',\n '.',\n 'u',\n 'l',\n 'p',\n 'w',\n 'm',\n 'i',\n 't',\n 'T',\n 's',\n 'n',\n 'd',\n 'y',\n 'o',\n 'e',\n 'f',\n 'r']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "m = 0\n",
    "n_step = 0\n",
    "n_hidden = 0\n",
    "\n",
    "class NNLM(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(NNLM, self).__init__()\n",
    "       self.embeddings = nn.Embedding(n_class, m) #embedding layer or look up table\n",
    "\n",
    "       self.hidden1 = nn.Linear(n_step * m, n_hidden, bias=False)\n",
    "       self.ones = nn.Parameter(torch.ones(n_hidden))\n",
    "\n",
    "       self.hidden2 = nn.Linear(n_hidden, n_class, bias=False)\n",
    "       self.hidden3 = nn.Linear(n_step * m, n_class, bias=False) #final layer\n",
    "\n",
    "       self.bias = nn.Parameter(torch.ones(n_class))\n",
    "\n",
    "   def forward(self, X):\n",
    "       X = self.embeddings(X) # embeddings\n",
    "       X = X.view(-1, n_step * m) # first layer\n",
    "       tanh = torch.tanh(self.d + self.hidden1(X)) # tanh layer\n",
    "       output = self.b + self.hidden3(X) + self.hidden2(tanh) # summing up all the layers with bias\n",
    "       return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CBOW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def CBOW(raw_text, window_size=2):\n",
    "   data = []\n",
    "   for i in range(window_size, len(raw_text) - window_size):\n",
    "       context = [raw_text[i - window_size], raw_text[i - (window_size - 1)], raw_text[i + (window_size - 1)], raw_text[i + window_size]]\n",
    "       target = raw_text[i]\n",
    "       data.append((context, target))\n",
    "\n",
    "   return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[(['T', 'h', 's', ' '], 'i'),\n (['h', 'i', ' ', 'i'], 's'),\n (['i', 's', 'i', 'n'], ' '),\n (['s', ' ', 'n', 't'], 'i'),\n ([' ', 'i', 't', 'r'], 'n'),\n (['i', 'n', 'r', 'o'], 't'),\n (['n', 't', 'o', 'd'], 'r'),\n (['t', 'r', 'd', 'u'], 'o'),\n (['r', 'o', 'u', 'c'], 'd'),\n (['o', 'd', 'c', 'e'], 'u'),\n (['d', 'u', 'e', 'd'], 'c'),\n (['u', 'c', 'd', ' '], 'e'),\n (['c', 'e', ' ', 'a'], 'd'),\n (['e', 'd', 'a', ' '], ' '),\n (['d', ' ', ' ', 'n'], 'a'),\n ([' ', 'a', 'n', 'e'], ' '),\n (['a', ' ', 'e', 'u'], 'n'),\n ([' ', 'n', 'u', 'r'], 'e'),\n (['n', 'e', 'r', 'a'], 'u'),\n (['e', 'u', 'a', 'l'], 'r'),\n (['u', 'r', 'l', ' '], 'a'),\n (['r', 'a', ' ', 'n'], 'l'),\n (['a', 'l', 'n', 'e'], ' '),\n (['l', ' ', 'e', 't'], 'n'),\n ([' ', 'n', 't', 'w'], 'e'),\n (['n', 'e', 'w', 'o'], 't'),\n (['e', 't', 'o', 'r'], 'w'),\n (['t', 'w', 'r', 'k'], 'o'),\n (['w', 'o', 'k', ' '], 'r'),\n (['o', 'r', ' ', 'a'], 'k'),\n (['r', 'k', 'a', 'r'], ' '),\n (['k', ' ', 'r', 'c'], 'a'),\n ([' ', 'a', 'c', 'h'], 'r'),\n (['a', 'r', 'h', 'i'], 'c'),\n (['r', 'c', 'i', 't'], 'h'),\n (['c', 'h', 't', 'e'], 'i'),\n (['h', 'i', 'e', 'c'], 't'),\n (['i', 't', 'c', 't'], 'e'),\n (['t', 'e', 't', 'u'], 'c'),\n (['e', 'c', 'u', 'r'], 't'),\n (['c', 't', 'r', 'e'], 'u'),\n (['t', 'u', 'e', ' '], 'r'),\n (['u', 'r', ' ', 'a'], 'e'),\n (['r', 'e', 'a', 'p'], ' '),\n (['e', ' ', 'p', 'p'], 'a'),\n ([' ', 'a', 'p', 'r'], 'p'),\n (['a', 'p', 'r', 'o'], 'p'),\n (['p', 'p', 'o', 'a'], 'r'),\n (['p', 'r', 'a', 'c'], 'o'),\n (['r', 'o', 'c', 'h'], 'a'),\n (['o', 'a', 'h', ' '], 'c'),\n (['a', 'c', ' ', 't'], 'h'),\n (['c', 'h', 't', 'h'], ' '),\n (['h', ' ', 'h', 'a'], 't'),\n ([' ', 't', 'a', 't'], 'h'),\n (['t', 'h', 't', ' '], 'a'),\n (['h', 'a', ' ', 'l'], 't'),\n (['a', 't', 'l', 'a'], ' '),\n (['t', ' ', 'a', 'i'], 'l'),\n ([' ', 'l', 'i', 'd'], 'a'),\n (['l', 'a', 'd', ' '], 'i'),\n (['a', 'i', ' ', 't'], 'd'),\n (['i', 'd', 't', 'h'], ' '),\n (['d', ' ', 'h', 'e'], 't'),\n ([' ', 't', 'e', ' '], 'h'),\n (['t', 'h', ' ', 'f'], 'e'),\n (['h', 'e', 'f', 'o'], ' '),\n (['e', ' ', 'o', 'u'], 'f'),\n ([' ', 'f', 'u', 'n'], 'o'),\n (['f', 'o', 'n', 'd'], 'u'),\n (['o', 'u', 'd', 'a'], 'n'),\n (['u', 'n', 'a', 't'], 'd'),\n (['n', 'd', 't', 'i'], 'a'),\n (['d', 'a', 'i', 'o'], 't'),\n (['a', 't', 'o', 'n'], 'i'),\n (['t', 'i', 'n', ' '], 'o'),\n (['i', 'o', ' ', 'f'], 'n'),\n (['o', 'n', 'f', 'o'], ' '),\n (['n', ' ', 'o', 'r'], 'f'),\n ([' ', 'f', 'r', ' '], 'o'),\n (['f', 'o', ' ', 'm'], 'r'),\n (['o', 'r', 'm', 'a'], ' '),\n (['r', ' ', 'a', 'n'], 'm'),\n ([' ', 'm', 'n', 'y'], 'a'),\n (['m', 'a', 'y', ' '], 'n'),\n (['a', 'n', ' ', 'c'], 'y'),\n (['n', 'y', 'c', 'u'], ' '),\n (['y', ' ', 'u', 'r'], 'c'),\n ([' ', 'c', 'r', 'r'], 'u'),\n (['c', 'u', 'r', 'e'], 'r'),\n (['u', 'r', 'e', 'n'], 'r'),\n (['r', 'r', 'n', 't'], 'e'),\n (['r', 'e', 't', ' '], 'n'),\n (['e', 'n', ' ', 'a'], 't'),\n (['n', 't', 'a', 'p'], ' '),\n (['t', ' ', 'p', 'p'], 'a'),\n ([' ', 'a', 'p', 'r'], 'p'),\n (['a', 'p', 'r', 'o'], 'p'),\n (['p', 'p', 'o', 'a'], 'r'),\n (['p', 'r', 'a', 'c'], 'o'),\n (['r', 'o', 'c', 'h'], 'a'),\n (['o', 'a', 'h', 'e'], 'c'),\n (['a', 'c', 'e', 's'], 'h'),\n (['c', 'h', 's', '.'], 'e'),\n (['h', 'e', '.', ' '], 's')]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBOW(raw_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CBOW_Model(torch.nn.Module):\n",
    "   def __init__(self, vocab_size, embedding_dim):\n",
    "       super(CBOW_Model, self).__init__()\n",
    "\n",
    "       self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "       self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "       self.activation_function1 = nn.ReLU()\n",
    "\n",
    "       self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "\n",
    "   def forward(self, inputs):\n",
    "       embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
    "       out = self.linear1(embeds)\n",
    "       out = self.activation_function1(out)\n",
    "       out = self.linear2(out)\n",
    "       return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}